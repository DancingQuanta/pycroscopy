{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PycroDataset\n",
    "============================================\n",
    "Suhas Somnath\n",
    "\n",
    "11/11/2017\n",
    "\n",
    "Introduction\n",
    "=========================\n",
    "We highly recommend reading about the pycroscopy data format - available in the docs.\n",
    "\n",
    "Pycroscopy uses a data-centric approach to data analysis and processing meaning that results from all data analysis and\n",
    "processing are written to the same h5 file that contains the recorded measurements. The Hierarchical Data Format (HDF5)\n",
    "allows data to be stored in multiple datasets in a tree-like manner. However, certain rules and considerations have\n",
    "been made in pycroscopy to ensure consistent and easy access to any data. pycroscopy.hdf_utils contains a lot of\n",
    "utility functions that simplify access to data and this tutorial provides an overview of many of the these functions\n",
    "\n",
    "* Other:\n",
    "    * print_tree <-- done\n",
    "* Searching / Lookup:\n",
    "    * find_dataset\n",
    "    * find_results_groups\n",
    "    * get_all_main\n",
    "    * get_auxillary_datasets\n",
    "    * get_group_refs\n",
    "    * get_h5_obj_refs\n",
    "    * get_source_dataset\n",
    "    * check_for_matching_attrs\n",
    "    * check_for_old\n",
    "* Main dataset - Reading:\n",
    "    * check_if_main <-- done\n",
    "    * get_data_descriptor\n",
    "    * reshape_to_n_dims\n",
    "    * reshape_to_2d\n",
    "* Ancillary datasets related:\n",
    "    * get_formatted_labels\n",
    "    * get_dimensionality\n",
    "    * get_sort_order\n",
    "    * get_unit_values\n",
    "* Attributes - Reading\n",
    "    * get_attr\n",
    "    * get_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Datasets via PycroDataset\n",
    "==============================\n",
    "\n",
    "For this example, we will be working with a Band Excitation Polarization Switching (BEPS) dataset acquired from\n",
    "advanced atomic force microscopes. In the much simpler Band Excitation (BE) imaging datasets, a single spectra is\n",
    "acquired at each location in a two dimensional grid of spatial locations. Thus, BE imaging datasets have two\n",
    "position dimensions (X, Y) and one spectroscopic dimension (frequency - against which the spectra is recorded).\n",
    "The BEPS dataset used in this example has a spectra for each combination of three other parameters (DC offset,\n",
    "Field, and Cycle). Thus, this dataset has three new spectral dimensions in addition to the spectra itself. Hence,\n",
    "this dataset becomes a 2+4 = 6 dimensional dataset\n",
    "\n",
    "In pycroscopy, all spatial dimensions are collapsed to a single dimension and similarly, all spectroscopic\n",
    "dimensions are also collapsed to a single dimension. Thus, the data is stored as a two-dimensional (N x P)\n",
    "matrix with N spatial locations each with P spectroscopic datapoints.\n",
    "\n",
    "This general and intuitive format allows imaging data from any instrument, measurement scheme, size, or\n",
    "dimensionality to be represented in the same way. Such an instrument independent data format enables a single\n",
    "set of analysis and processing functions to be reused for multiple image formats or modalities.\n",
    "\n",
    "Main datasets can be thought of as substantially more capable and information-packed than standard datasets\n",
    "since they have (or are linked to) all the necessary information to describe a measured dataset. The additional\n",
    "information contained / linked by Main datasets includes:\n",
    "\n",
    "* the recorded physical quantity\n",
    "* units of the data\n",
    "* names of the position and spectroscopic dimensions\n",
    "* dimensionality of the data in its original N dimensional form etc.\n",
    "\n",
    "While it is most certainly possible to access this information via the native h5py functionality, it can become\n",
    "tedious very quickly.  Pycroscopy's PycroDataset class makes such necessary information and any necessary\n",
    "functionality easily accessible.\n",
    "\n",
    "PycroDataset objects are still h5py.Dataset objects underneath, like all datasets accessed above, but add an\n",
    "additional layer of functionality to simplify data operations. Let's compare the information we can get via the\n",
    "standard h5py library with that from PycroDataset to see the additional layer of functionality. The PycroDataset\n",
    "makes the spectral and positional dimensions, sizes immediately apparent among other things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all necessary packages\n",
    "============================\n",
    "\n",
    "Before we begin demonstrating the numerous functiosn in pycroscopy.hdf_utils, we need to load the necessary packages. Here are a list of packages besides pycroscopy that will be used in this example:\n",
    "* h5py - to open and close the file\n",
    "* wget - to download the example data file\n",
    "* numpy - for numerical operations on arrays in memory\n",
    "* matplotlib - basic visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\PycharmProjects\\pycroscopy\\pycroscopy\\__init__.py:25: UserWarning: You are using the unity_dev branch, which is aimed at a 1.0 release for pycroscopy. Be advised - this branch changes very significantly and frequently. It is therefore not meant for usage. Use the master or dev branches for regular purposes.\n",
      "  warn('You are using the unity_dev branch, which is aimed at a 1.0 release for pycroscopy. '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import os\n",
    "# Warning package in case something goes wrong\n",
    "from warnings import warn\n",
    "# Package for downloading online files:\n",
    "try:\n",
    "    # This package is not part of anaconda and may need to be installed.\n",
    "    import wget\n",
    "except ImportError:\n",
    "    warn('wget not found.  Will install with pip.')\n",
    "    import pip\n",
    "    pip.main(['install', 'wget'])\n",
    "    import wget\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "if True:\n",
    "    import sys\n",
    "    sys.path.append(os.path.split(os.path.abspath('.'))[0])\n",
    "    import pycroscopy as px\n",
    "else:\n",
    "    try:\n",
    "        import pycroscopy as px\n",
    "    except ImportError:\n",
    "        warn('pycroscopy not found.  Will install with pip.')\n",
    "        import pip\n",
    "        pip.main(['install', 'pycroscopy'])\n",
    "        import pycroscopy as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset\n",
    "=========================================\n",
    "In order to demonstrate the many functions in hdf_utils, we will be using an pycroscopy HDF5 data file generated from an atomic force microscope containing real experimental data and some analysis results. First, let us download this file from the pycroscopy Github project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downloading the example file from the pycroscopy Github project\n",
    "url = 'https://raw.githubusercontent.com/pycroscopy/pycroscopy/master/data/BEPS_small.h5'\n",
    "h5_path = 'temp.h5'\n",
    "_ = wget.download(url, h5_path)\n",
    "\n",
    "print('Working on:\\n' + h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets open this HDF5 file in read-only mode. Note that opening the file does not cause the contents to be automatically loaded to memory. Instead, we are presented with objects that refer to specific HDF5 datasets, attributes or groups in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open the file in read-only mode\n",
    "h5_path = 'temp.h5'\n",
    "h5_f = h5py.File(h5_path, mode='r')\n",
    "# Here, h5_f is an active handle to the open file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the contents of this h5 data file\n",
    "=========================================\n",
    "\n",
    "The file contents are stored in a tree structure, just like files on a contemporary computer. The file contains\n",
    "datagroups (similar to file folders) and datasets (similar to spreadsheets).\n",
    "There are several datasets in the file and these store:\n",
    "\n",
    "* The actual measurement collected from the experiment\n",
    "* Spatial location on the sample where each measurement was collected\n",
    "* Information to support and explain the spectral data collected at each location\n",
    "* Since pycroscopy stores results from processing and analyses performed on the data in the same file, these\n",
    "  datasets and datagroups are present as well\n",
    "* Any other relevant ancillary information\n",
    "\n",
    "print_tree()\n",
    "------------\n",
    "Soon after opening any file, it is often of interest to list the contents of the file. While one can use the open\n",
    "source software HDFViewer developed by the HDF organization, pycroscopy.hdf_utils also has a very handy function - print_tree() to quickly visualize all the datasets and datagroups within the file within python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the H5 file:\n",
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Bin_FFT\n",
      "    ├ Bin_Frequencies\n",
      "    ├ Bin_Indices\n",
      "    ├ Bin_Step\n",
      "    ├ Bin_Wfm_Type\n",
      "    ├ Excitation_Waveform\n",
      "    ├ Noise_Floor\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "    ├ Spatially_Averaged_Plot_Group_000\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spatially_Averaged_Plot_Group_001\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ UDVS\n",
      "    ├ UDVS_Indices\n"
     ]
    }
   ],
   "source": [
    "print('Contents of the H5 file:')\n",
    "px.hdf_utils.print_tree(h5_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accessing the raw data\n",
    "pycro_main = main_dsets[0]\n",
    "print('Dataset as observed via h5py:')\n",
    "print()\n",
    "print('\\nDataset as seen via a PycroDataset object:')\n",
    "print(pycro_main)\n",
    "# Showing that the PycroDataset is still just a h5py.Dataset object underneath:\n",
    "print()\n",
    "print(isinstance(pycro_main, h5py.Dataset))\n",
    "print(pycro_main == h5_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Datasets via PycroDataset\n",
    "==============================\n",
    "\n",
    "For this example, we will be working with a Band Excitation Polarization Switching (BEPS) dataset acquired from\n",
    "advanced atomic force microscopes. In the much simpler Band Excitation (BE) imaging datasets, a single spectra is\n",
    "acquired at each location in a two dimensional grid of spatial locations. Thus, BE imaging datasets have two\n",
    "position dimensions (X, Y) and one spectroscopic dimension (frequency - against which the spectra is recorded).\n",
    "The BEPS dataset used in this example has a spectra for each combination of three other parameters (DC offset,\n",
    "Field, and Cycle). Thus, this dataset has three new spectral dimensions in addition to the spectra itself. Hence,\n",
    "this dataset becomes a 2+4 = 6 dimensional dataset\n",
    "\n",
    "In pycroscopy, all spatial dimensions are collapsed to a single dimension and similarly, all spectroscopic\n",
    "dimensions are also collapsed to a single dimension. Thus, the data is stored as a two-dimensional (N x P)\n",
    "matrix with N spatial locations each with P spectroscopic datapoints.\n",
    "\n",
    "This general and intuitive format allows imaging data from any instrument, measurement scheme, size, or\n",
    "dimensionality to be represented in the same way. Such an instrument independent data format enables a single\n",
    "set of analysis and processing functions to be reused for multiple image formats or modalities.\n",
    "\n",
    "Main datasets can be thought of as substantially more capable and information-packed than standard datasets\n",
    "since they have (or are linked to) all the necessary information to describe a measured dataset. The additional\n",
    "information contained / linked by Main datasets includes:\n",
    "\n",
    "* the recorded physical quantity\n",
    "* units of the data\n",
    "* names of the position and spectroscopic dimensions\n",
    "* dimensionality of the data in its original N dimensional form etc.\n",
    "\n",
    "While it is most certainly possible to access this information via the native h5py functionality, it can become\n",
    "tedious very quickly.  Pycroscopy's PycroDataset class makes such necessary information and any necessary\n",
    "functionality easily accessible.\n",
    "\n",
    "PycroDataset objects are still h5py.Dataset objects underneath, like all datasets accessed above, but add an\n",
    "additional layer of functionality to simplify data operations. Let's compare the information we can get via the\n",
    "standard h5py library with that from PycroDataset to see the additional layer of functionality. The PycroDataset\n",
    "makes the spectral and positional dimensions, sizes immediately apparent among other things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main datasets are often linked to supporting datasets in addition to the mandatory ancillary datasets.  The main\n",
    "dataset contains attributes which are references to these datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for att_name in pycro_main.attrs:\n",
    "    print(att_name, pycro_main.attrs[att_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets can be accessed easily via a handy hdf_utils function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(px.hdf_utils.getAuxData(pycro_main, auxDataName='Bin_FFT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional functionality of PycroDataset is enabled through several functions in hdf_utils. Below, we provide\n",
    "several such examples along with comparisons with performing the same operations in a simpler manner using\n",
    "the PycroDataset object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function to describe the nature of the contents within a dataset\n",
    "print(px.hdf_utils.get_data_descriptor(h5_raw))\n",
    "\n",
    "# this functionality can be accessed in PycroDatasets via:\n",
    "print(pycro_main.data_descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Ancillary Datasets\n",
    "========================\n",
    "\n",
    "As mentioned earlier, the ancillary datasets contain information about the dimensionality of the original\n",
    "N-dimensional dataset.  Here we see how we can extract the size and corresponding names of each of the spectral\n",
    "and position dimensions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# an alternate way to get the spectroscopic indices is simply via:\n",
    "print(pycro_main.h5_spec_inds)\n",
    "\n",
    "# We can get the spectral / position labels and dimensions easily via:\n",
    "print('Spectroscopic dimensions:')\n",
    "print(pycro_main.spec_dim_descriptors)\n",
    "print('Size of each dimension:')\n",
    "print(pycro_main.spec_dim_sizes)\n",
    "print('Position dimensions:')\n",
    "print(pycro_main.pos_dim_descriptors)\n",
    "print('Size of each dimension:')\n",
    "print(pycro_main.pos_dim_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When visualizing the data it is essential to plot the data against appropriate values on the X, Y, Z axes.\n",
    "Extracting a simple list or array of values to plot against may be challenging especially for multidimensional\n",
    "dataset such as the one under consideration. Fortunately, hdf_utils has a very handy function for this as well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5_spec_inds = px.hdf_utils.getAuxData(pycro_main, auxDataName='Spectroscopic_Indices')[0]\n",
    "h5_spec_vals = px.hdf_utils.getAuxData(pycro_main, auxDataName='Spectroscopic_Values')[0]\n",
    "dimension_name = 'DC_Offset'\n",
    "dc_dict = px.hdf_utils.get_unit_values(h5_spec_inds, h5_spec_vals, dim_names=dimension_name)\n",
    "print(dc_dict)\n",
    "dc_val = dc_dict[dimension_name]\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "axis.plot(dc_val)\n",
    "axis.set_title(dimension_name)\n",
    "axis.set_xlabel('Points in dimension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again, this process is simpler when using the PycroDataset object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv_val = pycro_main.get_spec_values(dim_name=dimension_name)\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "axis.plot(dc_val)\n",
    "axis.set_title(dimension_name)\n",
    "axis.set_xlabel('Points in dimension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping Data\n",
    "==============\n",
    "\n",
    "Pycroscopy stores N dimensional datasets in a flattened 2D form of position x spectral values. It can become\n",
    "challenging to retrieve the data in its original N-dimensional form, especially for multidimensional datasets\n",
    "such as the one we are working on. Fortunately, all the information regarding the dimensionality of the dataset\n",
    "are contained in the spectral and position ancillary datasets. hdf_utils has a very useful function that can\n",
    "help retrieve the N-dimensional form of the data using a simple function call:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndim_form, success, labels = px.hdf_utils.reshape_to_Ndims(h5_raw, get_labels=True)\n",
    "if success:\n",
    "    print('Succeeded in reshaping flattened 2D dataset to N dimensions')\n",
    "    print('Shape of the data in its original 2D form')\n",
    "    print(h5_raw.shape)\n",
    "    print('Shape of the N dimensional form of the dataset:')\n",
    "    print(ndim_form.shape)\n",
    "    print('And these are the dimensions')\n",
    "    print(labels)\n",
    "else:\n",
    "    print('Failed in reshaping the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole process is simplified further when using the PycroDataset object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndim_form = pycro_main.get_n_dim_form()\n",
    "print('Shape of the N dimensional form of the dataset:')\n",
    "print(ndim_form.shape)\n",
    "print('And these are the dimensions')\n",
    "print(pycro_main.n_dim_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Close and delete the h5_file\n",
    "h5_f.close()\n",
    "os.remove(h5_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
