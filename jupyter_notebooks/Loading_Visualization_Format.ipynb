{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading, reshaping, visualizing data using pycroscopy\n",
    "### Suhas Somnath, Chris R. Smith and Stephen Jesse\n",
    "The Center for Nanophase Materials Science and The Institute for Functional Imaging for Materials <br>\n",
    "Oak Ridge National Laboratory<br>\n",
    "8/01/2017\n",
    "\n",
    "Here, we will demonstrate how to load, reshape, and visualize multidimensional imaging datasets. For this example, we will load a three dimensional Band Excitation imaging dataset acquired from an atomic force microscope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure pycroscopy and wget are installed\n",
    "!pip install pycroscopy\n",
    "!pip install -U wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure python 3 compatibility\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import necessary libraries:\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import display\n",
    "from os import remove\n",
    "import pycroscopy as px\n",
    "\n",
    "# set up notebook to show plots within the notebook\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pycroscopy compatible file\n",
    "\n",
    "For simplicity we will use a dataset that has already been transalated form its original data format into a pycroscopy compatible hierarchical data format (HDF5 or H5) file\n",
    "\n",
    "#### HDF5 or H5 files:\n",
    "* are like smart containers that can store matrices with data, folders to organize these datasets, images, metadata like experimental parameters, links or shortcuts to datasets, etc.\n",
    "* are readily compatible with high-performance computing facilities\n",
    "* scale very efficiently from few kilobytes to several terabytes\n",
    "* can be read and modified using any language including Python, Matlab, C/C++, Java, Fortran, Igor Pro, etc.\n",
    "\n",
    "Python uses the h5py libaray to read, write, and access HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the example file from the pycroscopy Github project\n",
    "url = 'https://raw.githubusercontent.com/pycroscopy/pycroscopy/master/data/BELine_0004.h5'\n",
    "h5_path = 'temp.h5'\n",
    "_ = wget.download(url, h5_path)\n",
    "\n",
    "print('Working on:\\n' + h5_path)\n",
    "\n",
    "# Open the file in read-only mode\n",
    "h5_file = h5py.File(h5_path, mode='r')\n",
    "\n",
    "# Here, h5_file is an active handle to the open file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the contents of this h5 data file\n",
    "The file contents are stored in a tree structure, just like files on a contemporary computer. The file contains datagroups (similar to file folders) and datasets (similar to spreadsheets). \n",
    "\n",
    "There are several datasets in the file and these store:\n",
    "* the actual measurement collected from the experiment, \n",
    "* spatial location on the sample where each measurement was collected,\n",
    "* information to support and explain the spectral data collected at each location\n",
    "* Since pycroscopy stores results from processing and analyses performed on the data in the same file, these datasets and datagroups are present as well\n",
    "* any other relevant ancillary information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Datasets and datagroups within the file:\\n------------------------------------')\n",
    "px.hdf_utils.print_tree(h5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing datasests and datagroups\n",
    "\n",
    "Datasets and datagroups can be accessed by specifying the path, just like a webpage or a file in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Datagroup corresponding to a channel of information:')\n",
    "print(h5_file['/Measurement_000/Channel_000/'])\n",
    "\n",
    "print('\\nDataset containing the raw data collected from the microscope:')\n",
    "print(h5_file['/Measurement_000/Channel_000/Raw_Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that the \"Raw_Data\" dataset is a two dimensional dataset, and has complex value (a +bi) entries at each element in the 2D matrix.\n",
    "\n",
    "This dataset is contained in a datagroup called \"Channel_000\" which itself is contained in a datagroup called \"Measurement_000\"\n",
    "\n",
    "The datagroup \"Channel_000\" contains several \"members\", where these members could be datasets like \"Raw_Data\" or datagroups like \"Channel_000\"\n",
    "\n",
    "### Attributes\n",
    "HDF5 datasets and datagroups can also store metadata such as experimental parameters. These metadata can be text, numbers, small lists of numbers or text etc. These metadata can be very important for understanding the datasets and guide the analysis routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nMetadata or attributes in a datagroup\\n------------------------------------')\n",
    "for key in h5_file['/Measurement_000'].attrs:\n",
    "    print('{} : {}'.format(key, px.hdf_utils.get_attr(h5_file['/Measurement_000'], key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the spectral dataset under investigation, a spectra with a single peak was collected at each spatial location on a two dimensional grid of points. Thus, this dataset has two position dimensions and one spectroscopic dimension (spectra). \n",
    "\n",
    "In pycroscopy, all spatial dimensions are collapsed to a single dimension and similarly, all spectroscopic dimensions are also collapsed to a single dimension. Thus, the data is stored as a two-dimensional (N x P) matrix with N spatial locations each with P spectroscopic datapoints.\n",
    "\n",
    "This general and intuitive format allows imaging data from any instrument, measurement scheme, size, or dimensionality to be represented in the same way.\n",
    "\n",
    "Such an instrument independent data format enables a single set of anaysis and processing functions to be reused for multiple image formats or modalities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_chan_grp = h5_file['/Measurement_000/']\n",
    "h5_main = h5_chan_grp['Channel_000/Raw_Data']\n",
    "\n",
    "print('\\nThe main dataset:\\n------------------------------------')\n",
    "print(h5_main)\n",
    "print('Original three dimensional matrix had {} rows and {} columns \\\n",
    "each having {} spectral points'.format(h5_chan_grp.attrs['grid_num_rows'],\n",
    "                                       h5_chan_grp.attrs['grid_num_cols'],\n",
    "                                       h5_chan_grp.attrs['num_bins']))\n",
    "print('Collapsing the position dimensions: ({}x{}, {}) -> ({}, {})'.format(\n",
    "        h5_chan_grp.attrs['grid_num_rows'],\n",
    "        h5_chan_grp.attrs['grid_num_cols'],\n",
    "        h5_chan_grp.attrs['num_bins'],\n",
    "        h5_chan_grp.attrs['grid_num_rows'] * h5_chan_grp.attrs['grid_num_cols'],\n",
    "        h5_chan_grp.attrs['num_bins']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each main dataset is always accompanied by four ancillary datasets that explain:\n",
    "* the position and spectroscopic value of any given element in the dataset\n",
    "* the original dimensionality of the dataset\n",
    "* how to reshape the data back to its N dimensional form\n",
    "\n",
    "In the case of the 3d dataset under investigation, the positions will be arranged as row0-col0, row0-col1.... row0-colN, row1-col0....\n",
    "The spectroscopic information remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe ancillary datasets:\\n------------------------------------')\n",
    "print(h5_file['/Measurement_000/Channel_000/Position_Indices'])\n",
    "print(h5_file['/Measurement_000/Channel_000/Position_Values'])\n",
    "print(h5_file['/Measurement_000/Channel_000/Spectroscopic_Indices'])\n",
    "print(h5_file['/Measurement_000/Channel_000/Spectroscopic_Values'])\n",
    "\n",
    "print('\\nSpatial dimensions:', px.hdf_utils.get_attr(\n",
    "        h5_file['/Measurement_000/Channel_000/Position_Values'], 'labels'))\n",
    "print('Spectroscopic dimensions:', px.hdf_utils.get_attr(\n",
    "        h5_file['/Measurement_000/Channel_000/Spectroscopic_Values'], 'labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the position dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize=(6,6))\n",
    "axis.plot(h5_file['/Measurement_000/Channel_000/Position_Indices'][:, 0], \n",
    "          'orange', label='column')\n",
    "axis.plot(h5_file['/Measurement_000/Channel_000/Position_Indices'][:, 1], \n",
    "          'black', label='row')\n",
    "axis.legend()\n",
    "axis.set_title('Position Indices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the measurement at a single spatial pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a pixel index of interest\n",
    "pixel_ind = 128\n",
    "\n",
    "# ensuring that this index is within the bounds of the dataset\n",
    "pixel_ind = max(0, min(int(pixel_ind), h5_main.shape[0]))\n",
    "\n",
    "# Extracting the frequency vector (x-axis) to plot the spectra against\n",
    "freq_vec = h5_file['/Measurement_000/Channel_000/Bin_Frequencies'][()] * 1E-3\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(6,6))\n",
    "axis.plot(freq_vec, np.abs(h5_main[pixel_ind]))\n",
    "axis.set_xlabel('Frequency (kHz)')\n",
    "axis.set_ylabel('Amplitude (a. u.)')\n",
    "axis.set_title('Spectra at position {}'.format(pixel_ind));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the spatial distribution of the amplitude at a single frequency\n",
    "\n",
    "If the frequency is fixed, the spatial distribution would result in a 2D spatial map.\n",
    "\n",
    "Note that the spatial dimensions are collapsed to a single dimension in all pycroscopy datasets. Thus, the 1D vector at the specified frequency needs to be reshaped back to a 2D map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a pixel index of interest\n",
    "freq_ind = 40\n",
    "\n",
    "# ensuring that this index is within the bounds of the dataset\n",
    "freq_ind = max(0, min(int(freq_ind), h5_main.shape[1]))\n",
    "\n",
    "# extracting the position data (1D) at the spcified frequency index\n",
    "data_vec = np.abs(h5_main[:, freq_ind])\n",
    "\n",
    "# Constructing the 2D spatial map from the 1D vector:\n",
    "spat_map = np.reshape(data_vec, (h5_chan_grp.attrs['grid_num_rows'],\n",
    "                                 h5_chan_grp.attrs['grid_num_cols']))\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(6,6))\n",
    "axis.imshow(spat_map, cmap='inferno')\n",
    "axis.set_xlabel('Columns')\n",
    "axis.set_ylabel('Rows')\n",
    "\n",
    "freq_vec = h5_file['/Measurement_000/Channel_000/Bin_Frequencies'][()] * 1E-3\n",
    "axis.set_title('Amplitude at frequency {} kHz '.format(np.round(freq_vec[freq_ind], 2)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping data back to N dimensions\n",
    "\n",
    "There are several utility functions in pycroscopy that make it easy to access and reshape datasets. Here we show you how to return your dat to the N dimensional form in one easy step.\n",
    "\n",
    "While this data is a simple example and can be reshaped manually, such reshape operations become especially useful for 5,6,7 or larger dimensional datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim_data, success = px.hdf_utils.reshape_to_Ndims(h5_main)\n",
    "\n",
    "if not success:\n",
    "    print('There was a problem automatically reshaping the dataset. \\\n",
    "    Attempting to reshape manually')\n",
    "    ndim_data = np.reshape(h5_main[()], (h5_chan_grp.attrs['grid_num_rows'],\n",
    "                                         h5_chan_grp.attrs['grid_num_cols'],\n",
    "                                         h5_chan_grp.attrs['num_bins']))\n",
    "else:\n",
    "    print('Collapsed dataset originally of shape: ', h5_main.shape)\n",
    "    print('Reshaped dataset of shape: ', ndim_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The same data investigation can be performed on the N dimensional dataset:\n",
    "\n",
    "Here we will plot the spatial maps of the sample at a given frequency again. The reshape operation is no longer necessary and we get the same spatial map again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a pixel index of interest\n",
    "freq_ind = 40\n",
    "\n",
    "# ensuring that this index is within the bounds of the dataset\n",
    "freq_ind = max(0, min(int(freq_ind), h5_main.shape[1]))\n",
    "\n",
    "# Constructing the 2D spatial map from the 3D dataset\n",
    "spat_map = np.abs(ndim_data[:, :, freq_ind])\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(6,6))\n",
    "axis.imshow(spat_map, cmap='inferno')\n",
    "axis.set_xlabel('Columns')\n",
    "axis.set_ylabel('Rows')\n",
    "\n",
    "freq_vec = h5_file['/Measurement_000/Channel_000/Bin_Frequencies'][()] * 1E-3\n",
    "axis.set_title('Amplitude at frequency {} kHz '.format(np.round(freq_vec[freq_ind], 2)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the HDF5 file after data processing or visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the temporary data file:\n",
    "remove(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
