{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorials for Developing Scientific Workflows in Pycroscopy - Part 1: Data Translation\n",
    "\n",
    "#### Suhas Somnath\n",
    "8/8/2017\n",
    "\n",
    "This set of notebooks will serve as examples for developing and end-to-end workflows for and using pycroscopy. \n",
    "\n",
    "__In this example, we extract data and parameters from a Scanning Tunnelling Spectroscopy (STS) raw data file, as obtained from an Omicron STM, and write these to a pycroscopy compatible data file.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "Before proceeding with this example series, we recommend reading the previous documents to learn more about:\n",
    "1. Data and file formats\n",
    "    * Why you should care about data formats\n",
    "    * Current state of data formats in microscopy\n",
    "    * Structuring data in pycroscopy\n",
    "2. HDF5 file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Translation\n",
    "\n",
    "Before any data analysis, we need to access data stored in the raw file(s) generated by the microscope. Often, the data and parameters in these files are __not__ straightforward to access. In certain cases, additional / dedicated software packages are necessary to access the data while in many other cases, it is possible to extract the necessary information from built-in __numpy__ or similar python packages included with __anaconda__.\n",
    "\n",
    "Pycroscopy aims to make data access, storage, curation, etc. simply by storing the data along with all relevant parameters in a single __.hdf5__ or __.h5__ file. \n",
    "\n",
    "The process of copying data from the original format to __pycroscopy compatible hdf5 files__ is called __Translation__ and the classes available in pycroscopy that perform these operation are called __Translators__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your First Data Translator\n",
    "\n",
    "__The goal in this section is to trandslate the .asc file obtained from an Omicron microscope into a pycroscopy compatible .h5 file. __\n",
    "While there is an __AscTranslator__ avialable in pycroscopy that can translate these files in just a __single__ line, we will intentionally assume that no such translator is avialable. Using a handful of useful functions in pycroscopy, we will translate the files from the source __.asc__ format to the pycroscopy compatible __.h5__ in just a few lines. The code developed below is essentially the __AscTranslator__. The same methodology can be used to translate other data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the notebook\n",
    "\n",
    "There are a few setup procedures that need to be followed before any code is written. In this step, we simply load a few python packages that will be necessary in the latery steps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downloading packages:\n",
    "!pip install wget pycroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure python 3 compatibility:\n",
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "# In case some of these packages are not installed, install them\n",
    "#!pip install -U os wget numpy h5py matplotlib pycroscopy\n",
    "\n",
    "# The package for accessing files in directories, etc.:\n",
    "import os\n",
    "import wget\n",
    "\n",
    "# The mathematical computation package:\n",
    "import numpy as np\n",
    "\n",
    "# The package used for creating and manipulating HDF5 files:\n",
    "import h5py\n",
    "\n",
    "# Packages for plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Finally import pycroscopy for certain scientific analysis:\n",
    "import pycroscopy as px\n",
    "\n",
    "# set up notebook to show plots within the notebook\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Select the Raw Data File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the data file from Github:\n",
    "url = 'https://raw.githubusercontent.com/pycroscopy/pycroscopy/master/data/STS.asc'\n",
    "data_file_path = 'temp.asc'\n",
    "if os.path.exists(data_file_path):\n",
    "    os.remove(data_file_path)\n",
    "_ = wget.download(url, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploring the Raw Data File\n",
    "\n",
    "Inherently, one may not know how to read these __.asc__ files. One option is to try and read the file as a text file one line at a time. \n",
    "\n",
    "It turns out that these .asc files are effectively the standard __ASCII__ text files. \n",
    "\n",
    "Here is how we tested to see if the __asc__ files could be interpreted as text files. Below, we read just thefirst 10 lines in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(data_file_path, 'r') as file_handle:\n",
    "    for lin_ind in range(10):\n",
    "        print(file_handle.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the data\n",
    "\n",
    "Now that we know that these files are simple text files, we can manually go through the file to find out which lines are important, at what lines the data starts etc. \n",
    "\n",
    "Manual investigation of such .asc files revealed that these files are always formatted in the same way. Also, they contain parameters in the first 403 lines and then contain data which is arranged as one pixel per row.\n",
    "\n",
    "STS experiments result in 3 dimensional datasets (X, Y, current). In other words, a 1D array of current data (as a function of excitation bias) is sampled at every location on a two dimensional grid of points on the sample.\n",
    "\n",
    "By knowing where the parameters are located and how the data is structured, it is possible to extract the necessary information from these files.\n",
    "\n",
    "Since we know that the data sizes (<200 MB) are much smaler than the physical memory of most computers, we  can start by safely loading the contents of the entire file to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting the raw data into memory\n",
    "file_handle = open(data_file_path, 'r')\n",
    "string_lines = file_handle.readlines()\n",
    "file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read the parameters\n",
    "\n",
    "The parameters in these files are present in the first few lines of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading parameters stored in the first few rows of the file\n",
    "parm_dict = dict()\n",
    "for line in string_lines[3:17]:\n",
    "    line = line.replace('# ', '')\n",
    "    line = line.replace('\\n', '')\n",
    "    temp = line.split('=')\n",
    "    test = temp[1].strip()\n",
    "    try:\n",
    "        test = float(test)\n",
    "        # convert those values that should be integers:\n",
    "        if test % 1 == 0:\n",
    "            test = int(test)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    parm_dict[temp[0].strip()] = test\n",
    "\n",
    "# Print out the parameters extracted\n",
    "for key in parm_dict.keys():\n",
    "    print(key, ':\\t', parm_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a Prepare to read the data\n",
    "\n",
    "Before we read the data, we need to make an empty array to store all this data. In order to do this, we need to read the dictionary of parameters we made in step 2 and extract necessary quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = int(parm_dict['y-pixels'])\n",
    "num_cols = int(parm_dict['x-pixels'])\n",
    "num_pos = num_rows * num_cols\n",
    "spectra_length = int(parm_dict['z-points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Read the data\n",
    "\n",
    "Data is present after the first 403 lines of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_headers = len(string_lines) - num_pos\n",
    "num_headers = 403\n",
    "\n",
    "# Extract the STS data from subsequent lines\n",
    "raw_data_2d = np.zeros(shape=(num_pos, spectra_length), dtype=np.float32)\n",
    "for line_ind in range(num_pos):\n",
    "    this_line = string_lines[num_headers + line_ind]\n",
    "    string_spectrum = this_line.split('\\t')[:-1]  # omitting the new line\n",
    "    raw_data_2d[line_ind] = np.array(string_spectrum, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a Preparing some necessary parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_v = 1 # This is the one parameter we are not sure about\n",
    "\n",
    "folder_path, file_name = os.path.split(data_file_path)\n",
    "file_name = file_name[:-4] + '_'\n",
    "\n",
    "# Generate the x / voltage / spectroscopic axis:\n",
    "volt_vec = np.linspace(-1 * max_v, 1 * max_v, spectra_length)\n",
    "\n",
    "h5_path = os.path.join(folder_path, file_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Calling the NumpyTranslator to create the pycroscopy data file\n",
    "\n",
    "The NumpyTranslator simplifies the ceation of pycroscopy compatible datasets. It handles the file creation, dataset creation and writing, creation of ancillary datasets, datagroup creation, writing parameters, linking ancillary datasets to the main dataset etc. With a single call to the NumpyTranslator, we complete the translation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tran = px.io.NumpyTranslator()\n",
    "h5_path = tran.translate(h5_path, raw_data_2d, num_rows, num_cols, \n",
    "                         qty_name='Current', data_unit='nA', spec_name='Bias', \n",
    "                         spec_unit='V', spec_val=volt_vec, scan_height=100, \n",
    "                         scan_width=200, spatial_unit='nm', data_type='STS', \n",
    "                         translator_name='ASC', parms_dict=parm_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on pycroscopy translation\n",
    "* Steps 1-3 would be performed anyway in order to begin data analysis\n",
    "* The actual pycroscopy translation step are reduced to just 3-4 lines in step 4.\n",
    "* While this approach is feasible and encouraged for simple and small data, it may be necessary to use lower level calls to write efficient translators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the newly written H5 file:\n",
    "* We will only perform some simple and quick verification to show that the data has indeed been translated corectly. \n",
    "* Please see the next notebook in the example series to learn more about reading and accessing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(h5_path, mode='r') as h5_file:\n",
    "    # See if a tree has been created within the hdf5 file:\n",
    "    px.hdf_utils.print_tree(h5_file)\n",
    "    \n",
    "    h5_main = h5_file['Measurement_000/Channel_000/Raw_Data']\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(11,5))\n",
    "    spat_map = np.reshape(h5_main[:, 100], (100, 100))\n",
    "    px.plot_utils.plot_map(axes[0], spat_map, origin='lower')\n",
    "    axes[0].set_title('Spatial map')\n",
    "    axes[0].set_xlabel('X')\n",
    "    axes[0].set_ylabel('Y')\n",
    "    axes[1].plot(np.linspace(-1.0, 1.0, h5_main.shape[1]), \n",
    "                 h5_main[250])\n",
    "    axes[1].set_title('IV curve at a single pixel')\n",
    "    axes[1].set_xlabel('Tip bias [V]')\n",
    "    axes[1].set_ylabel('Current [nA]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove both the original and translated files:\n",
    "os.remove(h5_path)\n",
    "os.remove(data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next example  - Reading and Acessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
